{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tecnológico de Monterrey**\n",
    "\n",
    "#### **Maestría en Inteligencia Artificial Aplicada**\n",
    "#### **Clase**: Operaciones de Aprendizaje Automático\n",
    "#### **Docentes**: Dr. Gerardo Rodríguez Hernández | Mtro. Ricardo Valdez Hernández | Mtro. Carlos Alberto Vences Sánchez\n",
    "\n",
    "##### **Actividad**: Proyecto: Avance (Fase 1)\n",
    "##### **Equipo 25**:\n",
    "| Nombre | Matrícula |\n",
    "|--------|-----------|\n",
    "| Rafael Becerra García | A01796211 |\n",
    "| Andrea Xcaret Gómez Alfaro | A01796384 |\n",
    "| David Hernández Castellanos | A01795964 |\n",
    "| Juan Pablo López Sánchez | A01313663 |\n",
    "| Osiris Xcaret Saavedra Solís | A01795992 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    "\n",
    "**Analisis de Requerimientos**\n",
    "**Tarea**: Analiza la problemática a resolver siguiendo la liga con la descripción del dataset asignado.\n",
    "\n",
    "**Manipulación y preparación de datos**\n",
    "**Tarea**: Realizar tareas de Exploratory Data Analysis (EDA)  y limpieza de datos utilizando herramientas y bibliotecas específicas (Python, Pandas, DVC, Scikitlearn, etc.)\n",
    "\n",
    "**Exploración y preprocesamiento de datos**\n",
    "**Tarea**: Explorar y preprocesar los datos para identificar patrones, tendencias y relaciones significativas.\n",
    "\n",
    "**Versionado de datos**\n",
    "**Tarea**: Aplicar técnicas de versionado de datos para asegurar reproducibilidad y trazabilidad.\n",
    "\n",
    "**Construcción, ajuste y evaluación de Modelos de Machine Learning**\n",
    "**Tarea**: Construir, ajustar y evaluar modelos de Machine Learning utilizando técnicas y algoritmos apropiados al problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importaciones e inicializaciones --- #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración visual\n",
    "# sns.set(style='whitegrid')\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cargar Dataset --- #\n",
    "\n",
    "df = pd.read_csv('../data/processed/a01313663/obesity_estimation.csv')\n",
    "print('Dataset de trabajo (df)', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración inicial\n",
    "Revisar información general, tipos de datos, primeros registros y estadísticas descriptivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Revisión inicial --- #\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general y tipos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a69d6",
   "metadata": {},
   "source": [
    "### Correcciones\n",
    "Removemos columnas sin valor, corregimos datos en columnas, removemos valores atípicos obvios, imputamos valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Remover columna mixed_type_col ---#\n",
    "\n",
    "# Justificación:\n",
    "# - No tiene valores uniformes\n",
    "# - No parece guardar información que sea valiosa\n",
    "\n",
    "df.drop(columns=['mixed_type_col'], axis=1, inplace=True)\n",
    "\n",
    "# Confirmamos que la columna fue removida\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a306e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Corrección de tipos de datos --- #\n",
    "\n",
    "# Justificación:\n",
    "# Todas las columnas son identificadas como objeto, por lo cual es necesario revisar y corregir\n",
    "# los tipos de datos, para obtener datos adecuados en cada columna y poder actuar en ellos.\n",
    "\n",
    "# Según la página base del dataset, tenemos valores:\n",
    "# - Categóricos: Gender, CAEC, CALC, MTRANS, NObeyesdad\n",
    "# - Enteros: FCVC, TUE\n",
    "# - Flotantes: Age, Height, Weight, NCP, CH2O, FAF\n",
    "# - Binarios: family_history_with_overweight, FAVC, SMOKE, SCC\n",
    "\n",
    "# Sin embargo, de acuerdo a la exploración visual encontramos valores flotantes en FCVC y TUE, así que los consideraremos flotantes.\n",
    "numeric_cols = ['Age','Height','Weight','FCVC','NCP','CH2O','FAF','TUE']\n",
    "\n",
    "# Inspeccionemos los primeros 20 valores de cada columna numérica\n",
    "print(\"Valores en columnas numéricas:\\n\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"{col}: {df[col].unique()[:20]}\")\n",
    "\n",
    "# Columnas binarias (yes, no)\n",
    "binary_cols = ['family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC']\n",
    "\n",
    "# Inspeccionemos los primeros 20 valores de cada columna binaria\n",
    "print(\"\\nValores en columnas binarias:\\n\")\n",
    "for col in binary_cols:\n",
    "    print(f\"{col}: {df[col].unique()[:20]}\")\n",
    "\n",
    "# Columnas de tipo texto\n",
    "object_cols = ['Gender', 'CAEC', 'CALC', 'MTRANS', 'NObeyesdad']\n",
    "\n",
    "# Inspeccionemos los primeros 20 valores de cada columna de texto\n",
    "print(\"\\nValores en columnas de texto:\\n\")\n",
    "for col in object_cols:\n",
    "    print(f\"{col}: {df[col].unique()[:20]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9486bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Corrección y limpieza --- #\n",
    "\n",
    "# Justificación: encontramos algunas cosas irregulares, por ejemplo:\n",
    "# - Espacios en blanco alreadedor del valor numérico: ' 3.0 '\n",
    "# - Valores textuales: 'invalid' o ' NAN ' o '?'\n",
    "# - Encontramos diferentes cadenas con diferente construcción de mayúsculas y minúsculas\n",
    "\n",
    "# Convertir todas las columnas numéricas a float\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Convertimos las columnas que identificamos como binarias a valores binarios (0 y 1)\n",
    "binary_map = {'yes': 1, 'no': 0}\n",
    "for col in binary_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)              # Convertir todo a string\n",
    "        .str.strip()              # Eliminar espacios\n",
    "        .str.lower()              # Uniformar a minúsculas\n",
    "        .replace({'nan': np.nan}) # Convertir texto \"nan\"/\" NAN \" a NaN real\n",
    "        .map(binary_map)          # Mapear yes/no a 1/0\n",
    "    )\n",
    "\n",
    "# Convertir a enteros con soporte para NaN\n",
    "df[binary_cols] = df[binary_cols].astype('Int64')\n",
    "\n",
    "# Aplicamos strip y lower en todas las columnas de texto\n",
    "for col in object_cols:\n",
    "    df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Reemplazar valores no numéricos por NaN\n",
    "df.replace({'nan': np.nan, '?': np.nan, 'error': np.nan, 'invalid': np.nan, 'n/a': np.nan, 'null': np.nan}, inplace=True)\n",
    "\n",
    "# Verificar resultados\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validación visual ---#\n",
    "\n",
    "# Reimprimimos los valores de muestra una vez corregidos\n",
    "print(\"Valores en columnas numéricas:\\n\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"{col}: {df[col].unique()[:20]}\")\n",
    "\n",
    "# Inspeccionemos los primeros 20 valores de cada columna binaria\n",
    "print(\"\\nValores en columnas binarias:\\n\")\n",
    "for col in binary_cols:\n",
    "    print(f\"{col}: {df[col].unique()[:20]}\")\n",
    "\n",
    "# Inspeccionemos los primeros 20 valores de cada columna de texto\n",
    "print(\"\\nValores en columnas de texto:\\n\")\n",
    "for col in object_cols:\n",
    "    print(f\"{col}: {df[col].unique()[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filtrado de outliers obvios --- #\n",
    "\n",
    "# Justificación:\n",
    "# - Hay valores muy fuera de los esperados o simplemente inválidos\n",
    "\n",
    "# Definir rangos normales para cada columna numérica\n",
    "valid_ranges = {\n",
    "    'Age': (5, 120),         # años\n",
    "    'Height': (1.3, 2.2),    # metros\n",
    "    'Weight': (30, 200),     # kg\n",
    "    'FCVC': (1, 3),          # frecuencia comida principal\n",
    "    'NCP': (1, 3),           # número de comidas\n",
    "    'CH2O': (1, 3),          # litros de agua\n",
    "    'FAF': (0, 5),           # actividad física\n",
    "    'TUE': (0, 3)            # tiempo frente a pantalla\n",
    "}\n",
    "\n",
    "# Aplicar filtros: si el valor cae fuera del rango establecido como normal, poner NaN\n",
    "for col, (min_val, max_val) in valid_ranges.items():\n",
    "    df.loc[(df[col] < min_val) | (df[col] > max_val), col] = np.nan\n",
    "\n",
    "# Verificar resultados\n",
    "for col in valid_ranges.keys():\n",
    "    print(f\"{col}: valores únicos (primeros 20) después de filtrar outliers\")\n",
    "    print(df[col].unique()[:20])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imputación de NaN y limpieza final --- #\n",
    "\n",
    "# Columnas numéricas: imputar con mediana\n",
    "for col in numeric_cols:\n",
    "    median_value = df[col].median()\n",
    "    df[col] = df[col].fillna(median_value)\n",
    "    print(f\"Columna {col}: mediana imputada = {median_value}\")\n",
    "\n",
    "# Columnas categóricas: imputar con moda\n",
    "for col in object_cols:\n",
    "    mode_value = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(mode_value)\n",
    "    print(f\"Columna {col}: modo imputado = '{mode_value}'\")\n",
    "\n",
    "# Columnas binarias: imputar con moda\n",
    "for col in binary_cols:\n",
    "    moda = df[col].mode(dropna=True)[0]\n",
    "    df[col] = df[col].fillna(moda)\n",
    "\n",
    "# Buscar registros duplicados, es decir, que sean exactamente iguales\n",
    "dups = df.duplicated().sum()\n",
    "print(f'Registros duplicados: {dups}\\n')\n",
    "\n",
    "# En caso de encontrar alguno, eliminarlos\n",
    "if dups > 0:\n",
    "    print('Eliminando duplicados ...')\n",
    "    df = df.drop_duplicates()\n",
    "    dups = df.duplicated().sum()\n",
    "    print(f'Registros duplicados: {dups}\\n')\n",
    "\n",
    "# Veamos las nuevas dimensiones del dataset\n",
    "print('Nuevas dimensiones del dataset (df)', df.shape)\n",
    "\n",
    "# Verificación final\n",
    "print(\"\\nInformación final del dataset:\")\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2369ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Guardar versión limpia después del procesamiento realizado --- #\n",
    "\n",
    "# Generamos una copia del dataframe (df_clean) para continuar en ella el EDA\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Y versionamos nuestra copia limpia\n",
    "df_clean.to_csv('../data/processed/a01313663/obesity_estimation_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32621801",
   "metadata": {},
   "source": [
    "### Inspección Visual\n",
    "Revisemos las estadísticas por tipo de columna y el conteo de valores nulos por columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Estadísticas descriptivas --- #\n",
    "\n",
    "# Columnas numéricas\n",
    "display(df_clean[numeric_cols].describe())\n",
    "\n",
    "# Columnas binarias (estadísticas tipo object)\n",
    "display(df_clean[binary_cols].astype('object').describe())\n",
    "\n",
    "# Columnas de texto\n",
    "display(df_clean[object_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de nulos por columna\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5️⃣ Identificación de valores inconsistentes o outliers\n",
    "- Se pueden agregar funciones o visualizaciones específicas para detectar valores fuera de rango o inconsistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------===\n",
    "# 4️⃣ Visualización: EDA numérico completo\n",
    "# ----------------------------===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Columnas numéricas\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "# 1️⃣ Boxplots por columna\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "    plt.show()\n",
    "\n",
    "# 2️⃣ Histogramas con KDE\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.histplot(df[col], bins=30, kde=True)\n",
    "    plt.title(f'Histograma de {col} con KDE')\n",
    "    plt.show()\n",
    "\n",
    "# 3️⃣ Matriz de correlación\n",
    "plt.figure(figsize=(10,8))\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Matriz de correlación de variables numéricas\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------===\n",
    "# 5️⃣ EDA para columnas categóricas\n",
    "# ----------------------------===\n",
    "\n",
    "# Columnas categóricas\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    \n",
    "    # Conteo y proporción\n",
    "    counts = df[col].value_counts()\n",
    "    percents = df[col].value_counts(normalize=True) * 100\n",
    "    \n",
    "    # Mostrar en consola\n",
    "    print(f\"\\nColumna: {col}\")\n",
    "    print(\"Conteo de valores:\")\n",
    "    print(counts)\n",
    "    print(\"Porcentaje de cada categoría:\")\n",
    "    print(percents.round(2))\n",
    "    \n",
    "    # Gráfico de barras\n",
    "    sns.barplot(x=counts.index, y=counts.values)\n",
    "    plt.title(f'Conteo de categorías en {col}')\n",
    "    plt.ylabel('Cantidad de registros')\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6️⃣ Checklist de limpieza\n",
    "- Eliminar o imputar valores nulos\n",
    "- Corregir inconsistencias\n",
    "- Eliminar duplicados\n",
    "- Tratar outliers según criterio\n",
    "- Guardar la versión limpia y versionarla con DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: guardar versión limpia (después de aplicar limpieza)\n",
    "# df_clean = df.copy()  # aplicar limpieza aquí\n",
    "# df_clean.to_csv('data/processed/a01313663/obesity_estimation_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ecf788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------===\n",
    "# 6️⃣ Resumen completo de EDA\n",
    "# ----------------------------===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------\n",
    "# 1️⃣ Estadísticas descriptivas\n",
    "# ---------------------------------\n",
    "print(\"----= Estadísticas descriptivas (numéricas) ----=\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n----= Conteo de valores (categóricas) ----=\")\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    counts = df[col].value_counts()\n",
    "    percents = df[col].value_counts(normalize=True) * 100\n",
    "    print(f\"\\nColumna: {col}\")\n",
    "    print(\"Conteo de valores:\")\n",
    "    print(counts)\n",
    "    print(\"Porcentaje de cada categoría:\")\n",
    "    print(percents.round(2))\n",
    "\n",
    "# ---------------------------------\n",
    "# 2️⃣ Boxplots + Histogramas numéricos\n",
    "# ---------------------------------\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # Boxplot\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Histograma + KDE\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.histplot(df[col], bins=30, kde=True)\n",
    "    plt.title(f'Histograma de {col} con KDE')\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------------\n",
    "# 3️⃣ Correlación\n",
    "# ---------------------------------\n",
    "plt.figure(figsize=(10,8))\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Matriz de correlación de variables numéricas\")\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------\n",
    "# 4️⃣ Conteo visual de columnas categóricas\n",
    "# ---------------------------------\n",
    "for col in cat_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    counts = df[col].value_counts()\n",
    "    sns.barplot(x=counts.index, y=counts.values)\n",
    "    plt.title(f'Conteo de categorías en {col}')\n",
    "    plt.ylabel('Cantidad de registros')\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc5044",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
