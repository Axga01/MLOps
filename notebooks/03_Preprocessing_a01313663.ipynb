{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07cc46ab",
   "metadata": {},
   "source": [
    "### **Tecnológico de Monterrey**\n",
    "\n",
    "#### **Maestría en Inteligencia Artificial Aplicada**\n",
    "#### **Clase**: Operaciones de Aprendizaje Automático\n",
    "#### **Docentes**: Dr. Gerardo Rodríguez Hernández | Mtro. Ricardo Valdez Hernández | Mtro. Carlos Alberto Vences Sánchez\n",
    "\n",
    "##### **Actividad**: Proyecto: Avance (Fase 1) **Notebook**: Preprocesamiento de datos para análisis y modelado\n",
    "##### **Equipo 25**:\n",
    "| Nombre | Matrícula |\n",
    "|--------|-----------|\n",
    "| Rafael Becerra García | A01796211 |\n",
    "| Andrea Xcaret Gómez Alfaro | A01796384 |\n",
    "| David Hernández Castellanos | A01795964 |\n",
    "| Juan Pablo López Sánchez | A01313663 |\n",
    "| Osiris Xcaret Saavedra Solís | A01795992 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33964300",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    "\n",
    "**Analisis de Requerimientos**\n",
    "**Tarea**: Analiza la problemática a resolver siguiendo la liga con la descripción del dataset asignado.\n",
    "\n",
    "**Manipulación y preparación de datos**\n",
    "**Tarea**: Realizar tareas de Exploratory Data Analysis (EDA)  y limpieza de datos utilizando herramientas y bibliotecas específicas (Python, Pandas, DVC, Scikitlearn, etc.)\n",
    "\n",
    "**Exploración y preprocesamiento de datos**\n",
    "**Tarea**: Explorar y preprocesar los datos para identificar patrones, tendencias y relaciones significativas.\n",
    "\n",
    "**Versionado de datos**\n",
    "**Tarea**: Aplicar técnicas de versionado de datos para asegurar reproducibilidad y trazabilidad.\n",
    "\n",
    "**Construcción, ajuste y evaluación de Modelos de Machine Learning**\n",
    "**Tarea**: Construir, ajustar y evaluar modelos de Machine Learning utilizando técnicas y algoritmos apropiados al problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importaciones --- #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Configuración inicial\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = \"../data/processed/a01313663/obesity_estimation_clean.csv\"\n",
    "OUTPUT_DIR = \"../data/prepared/a01313663\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Carga del dataset limpio\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset de trabajo (df): {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383fe320",
   "metadata": {},
   "source": [
    "### Preprocesamiento para modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4287b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definiciones --- #\n",
    "\n",
    "# Variable objetivo\n",
    "target = \"NObeyesdad\"\n",
    "\n",
    "# Separar X (features) de y (target)\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "print(\"Variable objetivo:\", target)\n",
    "print(\"Número de variables predictoras:\", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82018511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Identificación de tipo de columnas ---#\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numéricas:\", num_cols)\n",
    "print(\"Categóricas:\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1af6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pipeline de preprocesamiento --- #\n",
    "\n",
    "# Escalador para variables numéricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Codificador para variables categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combinar transformaciones\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- División en conjuntos de entrenamiento, validación y pruebas --- #\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Aplicar transformaciones y generar datasets finales --- #\n",
    "\n",
    "# Ajustar y transformar\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Obtener nombres de las columnas resultantes\n",
    "cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(cat_cols)\n",
    "processed_feature_names = num_cols + list(cat_feature_names)\n",
    "\n",
    "# Crear DataFrames finales\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=processed_feature_names, index=X_train.index)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=processed_feature_names, index=X_test.index)\n",
    "\n",
    "# Añadir la variable objetivo\n",
    "train_df = pd.concat([X_train_df, y_train], axis=1)\n",
    "test_df = pd.concat([X_test_df, y_test], axis=1)\n",
    "\n",
    "print(\"Train final:\", train_df.shape)\n",
    "print(\"Test final:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836fc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Guardar datasets procesados y el preprocesador, para versionado --- #\n",
    "\n",
    "# Rutas de conjuntos y preprocesador\n",
    "train_path = os.path.join(OUTPUT_DIR, \"train_prepared.csv\")\n",
    "test_path = os.path.join(OUTPUT_DIR, \"test_prepared.csv\")\n",
    "preprocessor_path = os.path.join(OUTPUT_DIR, \"preprocessor.pkl\")\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "\n",
    "print(\"✅ Archivos guardados:\")\n",
    "print(\"-\", train_path)\n",
    "print(\"-\", test_path)\n",
    "print(\"-\", preprocessor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4728f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Revisión de las proporciones de la variable objetivo en ambos conjuntos --- #\n",
    "\n",
    "# Lista del orden deseado\n",
    "ordered_classes = [\n",
    "    'insufficient_weight',\n",
    "    'normal_weight',\n",
    "    'overweight_level_i',\n",
    "    'overweight_level_ii',\n",
    "    'obesity_type_i',\n",
    "    'obesity_type_ii',\n",
    "    'obesity_type_iii'\n",
    "]\n",
    "\n",
    "# Calcular proporciones\n",
    "train_dist = y_train.value_counts(normalize=True).round(3)\n",
    "test_dist = y_test.value_counts(normalize=True).round(3)\n",
    "\n",
    "# Crear DataFrame combinando train y test\n",
    "dist_df = pd.DataFrame({\n",
    "    'Train': train_dist,\n",
    "    'Test': test_dist\n",
    "})\n",
    "\n",
    "# Reordenar según el orden lógico\n",
    "dist_df = dist_df.reindex(ordered_classes)\n",
    "\n",
    "# Mostrar tabla\n",
    "dist_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc5044",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
