{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e71fcca",
   "metadata": {},
   "source": [
    "### **Tecnológico de Monterrey**\n",
    "\n",
    "#### **Maestría en Inteligencia Artificial Aplicada**\n",
    "#### **Clase**: Operaciones de Aprendizaje Automático\n",
    "#### **Docentes**: Dr. Gerardo Rodríguez Hernández | Mtro. Ricardo Valdez Hernández | Mtro. Carlos Alberto Vences Sánchez\n",
    "\n",
    "##### **Actividad**: Proyecto: Avance (Fase 1) **Notebook**: Modelo de aprendizaje automático\n",
    "##### **Equipo 25**:\n",
    "| Nombre | Matrícula |\n",
    "|--------|-----------|\n",
    "| Rafael Becerra García | A01796211 |\n",
    "| Andrea Xcaret Gómez Alfaro | A01796384 |\n",
    "| David Hernández Castellanos | A01795964 |\n",
    "| Juan Pablo López Sánchez | A01313663 |\n",
    "| Osiris Xcaret Saavedra Solís | A01795992 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889e3ed",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    "\n",
    "**Analisis de Requerimientos**\n",
    "**Tarea**: Analiza la problemática a resolver siguiendo la liga con la descripción del dataset asignado.\n",
    "\n",
    "**Manipulación y preparación de datos**\n",
    "**Tarea**: Realizar tareas de Exploratory Data Analysis (EDA)  y limpieza de datos utilizando herramientas y bibliotecas específicas (Python, Pandas, DVC, Scikitlearn, etc.)\n",
    "\n",
    "**Exploración y preprocesamiento de datos**\n",
    "**Tarea**: Explorar y preprocesar los datos para identificar patrones, tendencias y relaciones significativas.\n",
    "\n",
    "**Versionado de datos**\n",
    "**Tarea**: Aplicar técnicas de versionado de datos para asegurar reproducibilidad y trazabilidad.\n",
    "\n",
    "**Construcción, ajuste y evaluación de Modelos de Machine Learning**\n",
    "**Tarea**: Construir, ajustar y evaluar modelos de Machine Learning utilizando técnicas y algoritmos apropiados al problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45c9162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/08 11:37:58 INFO mlflow.tracking.fluent: Experiment with name 'Obesity_Classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados correctamente:\n",
      "Train: (1472, 23), Test: (632, 23)\n"
     ]
    }
   ],
   "source": [
    "# --- Inicialización --- #\n",
    "\n",
    "# Librerías\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    log_loss, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Configuración inicial\n",
    "DATA_DIR = \"../../data/prepared/a01313663\"\n",
    "MLFLOW_TRACKING_URI = \"mlruns\"\n",
    "EXPERIMENT_NAME = \"Obesity_Classification\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Remoción de advertencias\n",
    "os.environ[\"MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING\"] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\", message=\"l1_ratio parameter is only used when penalty is 'elasticnet'\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"The max_iter was reached which means the coef_ did not converge\")\n",
    "\n",
    "# Carga del dataset\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train_prepared.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test_prepared.csv\"))\n",
    "\n",
    "X_train = train_df.drop(columns=['NObeyesdad'])\n",
    "y_train = train_df['NObeyesdad']\n",
    "X_test = test_df.drop(columns=['NObeyesdad'])\n",
    "y_test = test_df['NObeyesdad']\n",
    "\n",
    "print(\"Datos cargados correctamente:\")\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c5c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Código utilitario --- #\n",
    "\n",
    "# Función para calcular métricas de evaluación de modelos\n",
    "def evaluate_model(y_true, y_pred, y_proba=None, average=\"macro\"):\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision_macro\": precision_score(y_true, y_pred, average=average, zero_division=0),\n",
    "        \"recall_macro\": recall_score(y_true, y_pred, average=average, zero_division=0),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=average, zero_division=0),\n",
    "        \"f1_weighted\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"mcc\": matthews_corrcoef(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            metrics[\"log_loss\"] = log_loss(y_true, y_proba)\n",
    "        except ValueError:\n",
    "            metrics[\"log_loss\"] = np.nan\n",
    "\n",
    "        try:\n",
    "            metrics[\"roc_auc_ovr\"] = roc_auc_score(y_true, y_proba, multi_class=\"ovr\")\n",
    "        except Exception:\n",
    "            metrics[\"roc_auc_ovr\"] = np.nan\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Función auxiliar para ejecución de modelos en MLflow\n",
    "def run_experiment(model, model_name, X_train, X_test, y_train, y_test, params=None):\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log de parámetros\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "        # Entrenamiento\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predicciones\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        # Evaluación\n",
    "        metrics = evaluate_model(y_test, y_pred, y_proba)\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Registro del modelo\n",
    "        input_example = X_train.head(1)\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            name=model_name,\n",
    "            input_example=input_example,\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "        print(f\"\\nResultados de {model_name}:\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"{k:20s}: {v:.4f}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea7d88",
   "metadata": {},
   "source": [
    "### Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd3222d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados de RandomForest:\n",
      "accuracy            : 0.9256\n",
      "precision_macro     : 0.9253\n",
      "recall_macro        : 0.9259\n",
      "f1_macro            : 0.9249\n",
      "f1_weighted         : 0.9258\n",
      "mcc                 : 0.9133\n",
      "log_loss            : 0.5945\n",
      "roc_auc_ovr         : 0.9877\n",
      "\n",
      "Resultados de GradientBoosting:\n",
      "accuracy            : 0.9272\n",
      "precision_macro     : 0.9263\n",
      "recall_macro        : 0.9276\n",
      "f1_macro            : 0.9265\n",
      "f1_weighted         : 0.9268\n",
      "mcc                 : 0.9151\n",
      "log_loss            : 0.3069\n",
      "roc_auc_ovr         : 0.9883\n",
      "\n",
      "Resultados de LogisticRegression:\n",
      "accuracy            : 0.8418\n",
      "precision_macro     : 0.8406\n",
      "recall_macro        : 0.8387\n",
      "f1_macro            : 0.8345\n",
      "f1_weighted         : 0.8382\n",
      "mcc                 : 0.8164\n",
      "log_loss            : 0.5417\n",
      "roc_auc_ovr         : 0.9731\n",
      "\n",
      "Resultados de SVC:\n",
      "accuracy            : 0.8782\n",
      "precision_macro     : 0.8749\n",
      "recall_macro        : 0.8768\n",
      "f1_macro            : 0.8753\n",
      "f1_weighted         : 0.8785\n",
      "mcc                 : 0.8579\n",
      "log_loss            : 0.3977\n",
      "roc_auc_ovr         : 0.9802\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>mcc</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.927215</td>\n",
       "      <td>0.926256</td>\n",
       "      <td>0.927610</td>\n",
       "      <td>0.926513</td>\n",
       "      <td>0.926763</td>\n",
       "      <td>0.915061</td>\n",
       "      <td>0.306879</td>\n",
       "      <td>0.988289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.925633</td>\n",
       "      <td>0.925342</td>\n",
       "      <td>0.925852</td>\n",
       "      <td>0.924916</td>\n",
       "      <td>0.925776</td>\n",
       "      <td>0.913349</td>\n",
       "      <td>0.594515</td>\n",
       "      <td>0.987733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.874942</td>\n",
       "      <td>0.876837</td>\n",
       "      <td>0.875251</td>\n",
       "      <td>0.878544</td>\n",
       "      <td>0.857939</td>\n",
       "      <td>0.397699</td>\n",
       "      <td>0.980196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841772</td>\n",
       "      <td>0.840577</td>\n",
       "      <td>0.838738</td>\n",
       "      <td>0.834468</td>\n",
       "      <td>0.838214</td>\n",
       "      <td>0.816359</td>\n",
       "      <td>0.541680</td>\n",
       "      <td>0.973108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  accuracy  precision_macro  recall_macro  f1_macro  \\\n",
       "1    GradientBoosting  0.927215         0.926256      0.927610  0.926513   \n",
       "0        RandomForest  0.925633         0.925342      0.925852  0.924916   \n",
       "3                 SVC  0.878165         0.874942      0.876837  0.875251   \n",
       "2  LogisticRegression  0.841772         0.840577      0.838738  0.834468   \n",
       "\n",
       "   f1_weighted       mcc  log_loss  roc_auc_ovr  \n",
       "1     0.926763  0.915061  0.306879     0.988289  \n",
       "0     0.925776  0.913349  0.594515     0.987733  \n",
       "3     0.878544  0.857939  0.397699     0.980196  \n",
       "2     0.838214  0.816359  0.541680     0.973108  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Modelo base y ejecución inicial --- #\n",
    "\n",
    "# Modelos a probar\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500, solver=\"saga\", random_state=42),\n",
    "    \"SVC\": SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    metrics = run_experiment(model, name, X_train, X_test, y_train, y_test)\n",
    "    results.append({\"Modelo\": name, **metrics})\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"accuracy\", ascending=False)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad9f629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ajustando RandomForest...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Mejores parámetros: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mejor f1_macro: 0.9216\n",
      "\n",
      "Ajustando GradientBoosting...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Mejores parámetros: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Mejor f1_macro: 0.9261\n",
      "\n",
      "Ajustando LogisticRegression...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Mejores parámetros: {'C': 10, 'l1_ratio': 1, 'penalty': 'elasticnet'}\n",
      "Mejor f1_macro: 0.8853\n",
      "\n",
      "Ajustando SVC...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Mejor f1_macro: 0.9276\n"
     ]
    }
   ],
   "source": [
    "# --- Ajuste de Hiperparámetros --- #\n",
    "\n",
    "# Grids con valores a usar\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\n",
    "        \"n_estimators\": [100, 300],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"]\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"learning_rate\": [0.05, 0.1],\n",
    "        \"max_depth\": [3, 5]\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10],\n",
    "        \"penalty\": [\"l2\", \"elasticnet\"],\n",
    "        \"l1_ratio\": [0, 0.5, 1]\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"kernel\": [\"linear\", \"rbf\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "scoring_metric = \"f1_macro\"\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nAjustando {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring=scoring_metric, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    print(f\"Mejores parámetros: {grid.best_params_}\")\n",
    "    print(f\"Mejor {scoring_metric}: {grid.best_score_:.4f}\")\n",
    "\n",
    "    input_example = X_train.head(1)\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "    # Registrar en MLflow\n",
    "    with mlflow.start_run(run_name=f\"{name}_tuned\"):\n",
    "        mlflow.log_params(grid.best_params_)\n",
    "        mlflow.log_metric(f\"best_cv_{scoring_metric}\", grid.best_score_)\n",
    "        mlflow.sklearn.log_model(grid.best_estimator_, name=\"model\", input_example=input_example, signature=signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e0b7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>mcc</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.935127</td>\n",
       "      <td>0.935252</td>\n",
       "      <td>0.935905</td>\n",
       "      <td>0.935209</td>\n",
       "      <td>0.935044</td>\n",
       "      <td>0.924303</td>\n",
       "      <td>0.533501</td>\n",
       "      <td>0.989059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.929499</td>\n",
       "      <td>0.930338</td>\n",
       "      <td>0.929452</td>\n",
       "      <td>0.930583</td>\n",
       "      <td>0.918827</td>\n",
       "      <td>0.595692</td>\n",
       "      <td>0.987649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.908228</td>\n",
       "      <td>0.907522</td>\n",
       "      <td>0.907282</td>\n",
       "      <td>0.905207</td>\n",
       "      <td>0.907262</td>\n",
       "      <td>0.893375</td>\n",
       "      <td>0.362204</td>\n",
       "      <td>0.985614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>0.888303</td>\n",
       "      <td>0.886752</td>\n",
       "      <td>0.885030</td>\n",
       "      <td>0.886123</td>\n",
       "      <td>0.869353</td>\n",
       "      <td>0.470277</td>\n",
       "      <td>0.979846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  accuracy  precision_macro  recall_macro  f1_macro  \\\n",
       "1    GradientBoosting  0.935127         0.935252      0.935905  0.935209   \n",
       "0        RandomForest  0.930380         0.929499      0.930338  0.929452   \n",
       "3                 SVC  0.908228         0.907522      0.907282  0.905207   \n",
       "2  LogisticRegression  0.887658         0.888303      0.886752  0.885030   \n",
       "\n",
       "   f1_weighted       mcc  log_loss  roc_auc_ovr  \n",
       "1     0.935044  0.924303  0.533501     0.989059  \n",
       "0     0.930583  0.918827  0.595692     0.987649  \n",
       "3     0.907262  0.893375  0.362204     0.985614  \n",
       "2     0.886123  0.869353  0.470277     0.979846  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejor modelo final: GradientBoosting\n",
      "Modelo guardado en: /models/best_model.pkl\n",
      "\n",
      "Matriz de Confusión:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insufficient_weight</th>\n",
       "      <th>normal_weight</th>\n",
       "      <th>obesity_type_i</th>\n",
       "      <th>obesity_type_ii</th>\n",
       "      <th>obesity_type_iii</th>\n",
       "      <th>overweight_level_i</th>\n",
       "      <th>overweight_level_ii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>insufficient_weight</th>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_weight</th>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obesity_type_i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obesity_type_ii</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obesity_type_iii</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overweight_level_i</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overweight_level_ii</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     insufficient_weight  normal_weight  obesity_type_i  \\\n",
       "insufficient_weight                   77              3               0   \n",
       "normal_weight                          5             75               0   \n",
       "obesity_type_i                         1              1             100   \n",
       "obesity_type_ii                        0              0               5   \n",
       "obesity_type_iii                       0              0               1   \n",
       "overweight_level_i                     0              0               1   \n",
       "overweight_level_ii                    0              1               1   \n",
       "\n",
       "                     obesity_type_ii  obesity_type_iii  overweight_level_i  \\\n",
       "insufficient_weight                0                 0                   0   \n",
       "normal_weight                      0                 0                   3   \n",
       "obesity_type_i                     2                 2                   2   \n",
       "obesity_type_ii                   84                 0                   0   \n",
       "obesity_type_iii                   1                94                   0   \n",
       "overweight_level_i                 1                 0                  77   \n",
       "overweight_level_ii                1                 0                   0   \n",
       "\n",
       "                     overweight_level_ii  \n",
       "insufficient_weight                    0  \n",
       "normal_weight                          1  \n",
       "obesity_type_i                         3  \n",
       "obesity_type_ii                        0  \n",
       "obesity_type_iii                       1  \n",
       "overweight_level_i                     5  \n",
       "overweight_level_ii                   84  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Guardar el mejor modelo --- #\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    metrics = evaluate_model(y_test, y_pred, y_proba)\n",
    "    final_results.append({\"Modelo\": name, **metrics})\n",
    "\n",
    "final_df = pd.DataFrame(final_results).sort_values(by=\"f1_macro\", ascending=False)\n",
    "display(final_df)\n",
    "\n",
    "best_model_name = final_df.iloc[0][\"Modelo\"]\n",
    "best_model = best_models[best_model_name]\n",
    "print(f\"\\nMejor modelo final: {best_model_name}\")\n",
    "\n",
    "os.makedirs(\"../../models/a01313663\", exist_ok=True)\n",
    "joblib.dump(best_model, f\"../../models/a01313663/best_model.pkl\")\n",
    "print(f\"Modelo guardado en: /models/a01313663/best_model.pkl\")\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, best_model.predict(X_test))\n",
    "cm_df = pd.DataFrame(cm, index=best_model.classes_, columns=best_model.classes_)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "display(cm_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc5044",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
